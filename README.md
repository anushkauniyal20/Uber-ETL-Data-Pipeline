# Uber-ETL-Data-Pipeline

**Project Overview**
This project demonstrates the end-to-end process of building a scalable data pipeline using Mage AI for ETL (Extract, Transform, Load) processes, integrated with Google Cloud Platform (GCP) for data storage, computation, and analytics. The final insights are visualized through an interactive dashboard created in Looker Studio (formerly Google Data Studio). The project showcases my ability to manage complex data workflows and deliver actionable insights using modern data engineering and cloud platforms.







**Key Features**

**ETL with Mage AI**: Extracted, transformed, and loaded large datasets using the Mage AI platform, ensuring efficient data processing and integration.

**Google Cloud Storage**: Used Google Cloud Storage for scalable and secure data storage solutions, enabling seamless interaction with the data pipeline.

**BigQuery for Data Warehousing**: Leveraged Google BigQuery for fast, SQL-based querying of large datasets, optimizing performance for real-time analytics.

**Compute Instance for Task Automation**: Deployed a Google Compute Engine instance to automate data ingestion and processing tasks, ensuring a reliable and scalable pipeline.

**Looker Studio for Dashboarding**: Built an intuitive and interactive dashboard on Looker Studio to visualize key insights and trends from the processed data.

**Python for Custom Logic**: Developed Python scripts to handle custom data transformation logic, integrating seamlessly with the Mage AI workflows.

**Architecture**
![Image](https://github.com/user-attachments/assets/40c51596-d8a1-460e-a14b-2df15f833517)


**Data Model**
![Image](https://github.com/user-attachments/assets/97c53d24-da03-4e7b-af93-9cb83477558d)
